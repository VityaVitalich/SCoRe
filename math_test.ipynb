{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils/')\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from huggingface_hub import notebook_login\n",
    "from utils.math_grader import grade_answer\n",
    "from utils.qwen_math_parser import extract_answer\n",
    "import re\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForCausalLM, GenerationConfig\n",
    "from prompts import get_prompt_builder\n",
    "from prompts.prompt_schemas import load_few_shot_prompts\n",
    "from utils.eval_utils import RewardEvaluator\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from trl.trainer.utils import batch_generation\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_path': 'Qwen/Qwen2.5-Math-1.5B-Instruct',\n",
    "    'data_path': 'data/datasets/math500_level1',\n",
    "    'cache_dir': '/home/data/v.moskvoretskii/cache/',\n",
    "    'task_type': 'math',\n",
    "    'few_shot_dir': 'few_shots',\n",
    "    'question_col': 'problem',\n",
    "    'gold_col': 'answer'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        config['model_path'],\n",
    "        cache_dir=config['cache_dir'],\n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        config['model_path'],\n",
    "        use_fast=True,\n",
    "        cache_dir=config['cache_dir']\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([[151644,   8948,    198,   5501,   2874,   3019,    553,   3019,     11,                                                                                                                            \n",
    "            323,   2182,    697,   1590,   4226,   2878,   1124,  79075,   2979,                                                                                                                            \n",
    "           3417, 151645,    198, 151644,    872,    198,   9885,    279,  30232,                                                                                                                            \n",
    "            315,    279,   1555,    400,     18,     87,     10,     20,     88,                                                                                                                            \n",
    "             28,     17,     15,      3,    624, 151645,    198, 151644,  77091,                                                                                                                            \n",
    "            198,   1249,   1477,    279,  30232,    315,    279,   1555,   2661,                                                                                                                            \n",
    "            553,    279,  23606,  17767,     18,     87,    488,    220,     20,                                                                                                                            \n",
    "             88,    284,    220,     17,     15,     59,    701,    582,   1184,                                                                                                                            \n",
    "            311,  18130,    279,  23606,    304,    279,  30232,  44894,   1484,                                                                                                                            \n",
    "           1352,     11,    892,    374,  17767,     88,    284,  14619,    488,                                                                                                                            \n",
    "            293,     59,    568,    758,    419,   1352,     11,  17767,     76,                                                                                                                            \n",
    "          57758,  10868,    279,  30232,    315,    279,   1555,    382,  10061,                                                                                                                            \n",
    "            594,   1191,    448,    279,   2661,  23606,    510,  78045,     18,                                                                                                                            \n",
    "             87,    488,    220,     20,     88,    284,    220,     17,     15,                                                                                                                            \n",
    "             59,   2533,   1654,   1366,    311,  11625,    369,  17767,     88,                                                                                                                            \n",
    "             59,    568,   5512,     11,  42123,    279,  17767,     88,     59,                                                                                                                            \n",
    "           7287,   4991,    553,  32256,    287,  17767,     18,     87,  57758,                                                                                                                            \n",
    "            504,   2176,  11067,    315,    279,  23606,    510,  78045,     20,                                                                                                                            \n",
    "             88,    284,    481,     18,     87,    488,    220,     17,     15,                                                                                                                            \n",
    "             59,   2533,   5847,     11,  21749,   1449,   4647,    553,    220,                                                                                                                            \n",
    "             20,    311,  11625,    369,  17767,     88,     59,    982,  78045,                                                                                                                            \n",
    "             88,    284,    481,     59,  37018,     90,     18,  15170,     20,                                                                                                                            \n",
    "             92,     87,    488,    220,     19,     59,   2533,   7039,    279,                                                                                                                            \n",
    "          23606,    374,    304,    279,  30232,  44894,   1484,   1352,  17767,                                                                                                                            \n",
    "             88,    284,  14619,    488,    293,     59,    701,   1380,    279,                                                                                                                            \n",
    "          35606,    315,  17767,     87,  57758,    374,    279,  30232,  17767,                                                                                                                            \n",
    "             76,     59,    568,   5542,    279,  23606,  17767,     88,    284,                                                                                                                            \n",
    "            481,     59,  37018,     90,     18,  15170,     20,     92,     87,                                                                                                                            \n",
    "            488,    220,     19,     59,    701,    582,    646,   1490,    429,                                                                                                                            \n",
    "            279,  30232,  17767,     76,  57758,    374,   1124,   4080,     59,                                                                                                                            \n",
    "          37018,     90,     18,  15170,     20,  11035,   3593,  54815,     11,                                                                                                                            \n",
    "            279,  30232,    315,    279,   1555,    374,   1124,  11520,  79075,                                                                                                                            \n",
    "          19999,     59,  37018,     90,     18,  15170,     20,   3417,     59,                                                                                                                            \n",
    "            568, 151645,    198, 151644,    872,    198,   3862,   2578,    387,                                                                                                                            \n",
    "            458,   1465,    304,    279,   6291,   3403,   1576,    315,   6853,                                                                                                                            \n",
    "            315,   8660,    315,    279,   3405,     13,   5209,   4396,    279,                                                                                                                            \n",
    "           1465,     11,    421,    894,     11,    323,  18130,    279,   6291,                                                                                                                            \n",
    "             13,  10224,    697,   1590,   4226,   2878,   1124,  79075,   2979,\n",
    "           3417, 151645,    198, 151644,  77091,    198]]).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_new_tokens=20, top_p=0.8, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<|im_start|>system\\nPlease reason step by step, and put your final answer within \\\\boxed{{}}<|im_end|>\\n<|im_start|>user\\nFind the slope of the line $3x+5y=20$.\\n<|im_end|>\\n<|im_start|>assistant\\nTo find the slope of the line given by the equation \\\\(3x + 5y = 20\\\\), we need to rewrite the equation in the slope-intercept form, which is \\\\(y = mx + b\\\\). In this form, \\\\(m\\\\) represents the slope of the line.\\n\\nLet's start with the given equation:\\n\\\\[3x + 5y = 20\\\\]\\n\\nWe want to solve for \\\\(y\\\\). First, isolate the \\\\(y\\\\)-term by subtracting \\\\(3x\\\\) from both sides of the equation:\\n\\\\[5y = -3x + 20\\\\]\\n\\nNext, divide every term by 5 to solve for \\\\(y\\\\):\\n\\\\[y = -\\\\frac{3}{5}x + 4\\\\]\\n\\nNow the equation is in the slope-intercept form \\\\(y = mx + b\\\\), where the coefficient of \\\\(x\\\\) is the slope \\\\(m\\\\). From the equation \\\\(y = -\\\\frac{3}{5}x + 4\\\\), we can see that the slope \\\\(m\\\\) is \\\\(-\\\\frac{3}{5}\\\\).\\n\\nTherefore, the slope of the line is \\\\(\\\\boxed{-\\\\frac{3}{5}}\\\\).<|im_end|>\\n<|im_start|>user\\nThere might be an error in the solution above because of lack of understanding of the question. Please correct the error, if any, and rewrite the solution. Put your final answer within \\\\boxed{{}}<|im_end|>\\n<|im_start|>assistant\\nLet's go through the steps again to ensure clarity and correctness.\\n\\nWe start with the given equation:\\n\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading tokenizer from: Qwen/Qwen2.5-0.5B-Instruct\n",
      "[INFO] No few-shot file found for prompt_type='math_initial' at 'few_shots/math_initial.json'. Using none.\n"
     ]
    }
   ],
   "source": [
    "def add_input_ids(example, prompt_func):\n",
    "    input_ids = prompt_func(example)\n",
    "    example['input_ids'] = input_ids\n",
    "    return example\n",
    "\n",
    "ds = datasets.load_from_disk(config['data_path'])\n",
    "\n",
    "# 3) Initialize the tokenizer\n",
    "print(f\"[INFO] Loading tokenizer from: {config['model_path']}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    config['model_path'],\n",
    "    use_fast=True,\n",
    "    cache_dir=config['cache_dir']\n",
    "\n",
    ")\n",
    "\n",
    "# 4) Load the prompt builder + few-shot\n",
    "prompt_builder = get_prompt_builder(config['task_type'])\n",
    "initial_generation_few_shot = load_few_shot_prompts(\n",
    "    config['few_shot_dir'],\n",
    "    f\"{config['task_type']}_initial\"\n",
    ")\n",
    "\n",
    "initial_generation_prompt_func = partial(\n",
    "    prompt_builder.build_initial_generation_prompt,\n",
    "    tokenizer=tokenizer,\n",
    "    question_col=config['question_col'],\n",
    "    few_shot_prompts=initial_generation_few_shot,\n",
    "    tokenize=True\n",
    ")\n",
    "\n",
    "ds = ds.map(partial(add_input_ids, prompt_func=initial_generation_prompt_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'] = ds['train'].select_columns([config['question_col'], config['gold_col'], 'input_ids'])\n",
    "ds['test'] = ds['test'].select_columns([config['question_col'], config['gold_col'], 'input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def custom_collate_fn(features, config):\n",
    "    # 1) Extract the text columns you want to keep\n",
    "    #    but do NOT pass them to the default collator\n",
    "    text_cols = [config['gold_col'], config['question_col']]\n",
    "    batch_text = {}\n",
    "    for col in text_cols:\n",
    "        batch_text[col] = [f[col] for f in features]  # gather them as a list\n",
    "\n",
    "    # 3) Use the default HF collator to pad the numeric parts only\n",
    "    model_batch = collator([{'input_ids': f['input_ids']} for f in features])\n",
    "\n",
    "    # 4) Attach the text lists back to the batch, as Python lists\n",
    "    model_batch.update(batch_text)\n",
    "\n",
    "    return model_batch\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ds['train'],\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=partial(custom_collate_fn, config=config),\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,   5501,   2874,   3019,\n",
       "            553,   3019,     11,    323,   2182,    697,   1590,   4226,   2878,\n",
       "           1124,  79075,   2979,   3417, 151645,    198, 151644,    872,    198,\n",
       "             35,  24308,    279,  26313,    315,    220,     22,     16,    320,\n",
       "           2593,    220,     18,   4292, 151645,    198, 151644,  77091,    198,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643],\n",
       "        [151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,   5501,   2874,   3019,\n",
       "            553,   3019,     11,    323,   2182,    697,   1590,   4226,   2878,\n",
       "           1124,  79075,   2979,   3417, 151645,    198, 151644,    872,    198,\n",
       "           2679,    400,     69,   2075,  15087,    374,    458,   1496,    729,\n",
       "            323,    400,     70,   2075,  15087,    374,    458,  10322,    729,\n",
       "             11,   1477,    421,    400,     69,   3268,   2075,     61,     18,\n",
       "            593,      3,    374,   1496,     11,  10322,     11,    476,  13866,\n",
       "            382,   6269,    330,  14556,    497,    330,  16788,    497,    476,\n",
       "            330,    811,   2485,  22956, 151645,    198, 151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]]), 'answer': ['2', '\\\\text{even}'], 'problem': ['Determine the remainder of 71 (mod 3).', 'If $f(x)$ is an even function and $g(x)$ is an odd function, find if $f(g(x^3))$ is even, odd, or neither.\\n\\nEnter \"odd\", \"even\", or \"neither\".']}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(config['model_path'], cache_dir=config['cache_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    }
   ],
   "source": [
    "init_generation_config = GenerationConfig(\n",
    "            max_new_tokens=4,  # or some separate param, e.g. args.initial_answer_length\n",
    "            temperature=1.0,\n",
    "            top_k=0,\n",
    "            top_p=1.0,\n",
    "            do_sample=True,\n",
    "            pad_token_id=None,\n",
    "            eos_token_id=None,\n",
    "        )\n",
    "\n",
    "init_outputs, init_logits = batch_generation(\n",
    "                        model,\n",
    "                        batch['input_ids'],\n",
    "                        2,\n",
    "                        tokenizer.pad_token_id,\n",
    "                        init_generation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_len = batch['input_ids'].shape[1]\n",
    "init_answers = init_outputs[:, context_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' To determine the remainder', 'To determine whether the']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(init_answers, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_correction_inputs_for_batch(\n",
    "    batch,\n",
    "    init_answer_tokens: torch.Tensor,\n",
    "    tokenizer,\n",
    "    prompt_builder,\n",
    "    collator,\n",
    "    question_col: str = \"question\",\n",
    "    initial_answer_col: str = \"initial_answer\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a batch of data (each row containing the question text), plus the\n",
    "    model's initial answer tokens (init_answer_tokens) for each row,\n",
    "    this function:\n",
    "\n",
    "      1) Decodes each row's initial answer tokens -> string.\n",
    "      2) Calls prompt_builder.build_correction_prompt(...) with that text,\n",
    "         producing the final correction prompt text.\n",
    "      3) Tokenizes that correction prompt text.\n",
    "\n",
    "    Returns:\n",
    "      A list of dicts, each containing:\n",
    "         {\n",
    "           \"input_ids\": ...,\n",
    "           \"attention_mask\": ...,\n",
    "           \"prompt_text\": ...,\n",
    "           \"question\": ...,\n",
    "           \"init_answer_text\": ...\n",
    "         }\n",
    "      or whatever structure you need for your next forward pass.\n",
    "    \"\"\"\n",
    "\n",
    "    # init_answer_tokens shape is [batch_size, seq_len_of_initial]\n",
    "    # We'll decode row-by-row\n",
    "    init_answer_texts = tokenizer.batch_decode(init_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "    # We will store the final \"correction input\" for each row\n",
    "    batch_correction_inputs = []\n",
    "\n",
    "    for i, init_ans_text in enumerate(init_answer_texts):\n",
    "        question_text = batch[question_col][i]\n",
    "\n",
    "        # Build a 'sample' dict as your prompt_builder expects:\n",
    "        sample_for_prompt = {\n",
    "            question_col: question_text,\n",
    "            initial_answer_col: [init_ans_text],  # your builder uses a list for initial answers\n",
    "        }\n",
    "\n",
    "        # Now get the final correction prompt(s). Typically there's 1 prompt\n",
    "        # in this scenario, but build_correction_prompt returns a list.\n",
    "        corr_inputs = prompt_builder.build_correction_prompt(\n",
    "            sample=sample_for_prompt,\n",
    "            tokenizer=tokenizer,\n",
    "            question_col=question_col,\n",
    "            initial_answer_col=initial_answer_col,\n",
    "            tokenize=True\n",
    "        )\n",
    "        # Since we used only 1 initial answer, corr_prompts[0] is the final text\n",
    "        corr_inputs = corr_inputs[0]\n",
    "\n",
    "        batch_correction_inputs.append({'input_ids': corr_inputs})\n",
    "\n",
    "\n",
    "    collated_corrections = collator(batch_correction_inputs)\n",
    "    batch['correction_input_ids'] = collated_corrections['input_ids']\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_correction_inputs = build_correction_inputs_for_batch(\n",
    "    batch, \n",
    "    init_answers,\n",
    "    tokenizer,\n",
    "    prompt_builder,\n",
    "    collator,\n",
    "    question_col='problem',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,   5501,   2874,   3019,\n",
       "            553,   3019,     11,    323,   2182,    697,   1590,   4226,   2878,\n",
       "           1124,  79075,   2979,   3417, 151645,    198, 151644,    872,    198,\n",
       "             35,  24308,    279,  26313,    315,    220,     22,     16,    320,\n",
       "           2593,    220,     18,   4292, 151645,    198, 151644,  77091,    198,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643],\n",
       "        [151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,   5501,   2874,   3019,\n",
       "            553,   3019,     11,    323,   2182,    697,   1590,   4226,   2878,\n",
       "           1124,  79075,   2979,   3417, 151645,    198, 151644,    872,    198,\n",
       "           2679,    400,     69,   2075,  15087,    374,    458,   1496,    729,\n",
       "            323,    400,     70,   2075,  15087,    374,    458,  10322,    729,\n",
       "             11,   1477,    421,    400,     69,   3268,   2075,     61,     18,\n",
       "            593,      3,    374,   1496,     11,  10322,     11,    476,  13866,\n",
       "            382,   6269,    330,  14556,    497,    330,  16788,    497,    476,\n",
       "            330,    811,   2485,  22956, 151645,    198, 151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]]), 'problem': ['Determine the remainder of 71 (mod 3).', 'If $f(x)$ is an even function and $g(x)$ is an odd function, find if $f(g(x^3))$ is even, odd, or neither.\\n\\nEnter \"odd\", \"even\", or \"neither\".'], 'solution': ['$71 = 23 \\\\cdot 3 + 2 \\\\Rightarrow 71 \\\\equiv \\\\boxed{2} \\\\pmod{3}$.', 'Substituting $-x$ for $x$ gives us $f(g(-x^3)) = f(-g(x^3)) = f(g(x^3))$ so $f(g(x^3))$ is $\\\\boxed{\\\\text{even}}$.'], 'answer': ['2', '\\\\text{even}'], 'subject': ['Number Theory', 'Intermediate Algebra'], 'level': [1, 1], 'unique_id': ['test/number_theory/81.json', 'test/intermediate_algebra/1230.json'], '__index_level_0__': [13, 19], 'correction_input_ids': tensor([[151644,   8948,    198,   5501,   2874,   3019,    553,   3019,     11,\n",
       "            323,   2182,    697,   1590,   4226,   2878,   1124,  79075,   2979,\n",
       "           3417, 151645,    198, 151644,    872,    198,     35,  24308,    279,\n",
       "          26313,    315,    220,     22,     16,    320,   2593,    220,     18,\n",
       "           4292, 151645,    198, 151644,  77091,    198,   2014,   8253,    279,\n",
       "          26313, 151645,    198, 151644,    872,    198,   3862,   2578,    387,\n",
       "            458,   1465,    304,    279,   6291,   3403,   1576,    315,   6853,\n",
       "            315,   8660,    315,    279,   3405,     13,   5209,   4396,    279,\n",
       "           1465,     11,    421,    894,     11,    323,  18130,    279,   6291,\n",
       "             13,  10224,    697,   1590,   4226,   2878,   1124,  79075,   2979,\n",
       "           3417, 151645,    198, 151644,  77091,    198, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643],\n",
       "        [151644,   8948,    198,   5501,   2874,   3019,    553,   3019,     11,\n",
       "            323,   2182,    697,   1590,   4226,   2878,   1124,  79075,   2979,\n",
       "           3417, 151645,    198, 151644,    872,    198,   2679,    400,     69,\n",
       "           2075,  15087,    374,    458,   1496,    729,    323,    400,     70,\n",
       "           2075,  15087,    374,    458,  10322,    729,     11,   1477,    421,\n",
       "            400,     69,   3268,   2075,     61,     18,    593,      3,    374,\n",
       "           1496,     11,  10322,     11,    476,  13866,    382,   6269,    330,\n",
       "          14556,    497,    330,  16788,    497,    476,    330,    811,   2485,\n",
       "          22956, 151645,    198, 151644,  77091,    198,   1249,   8253,   3425,\n",
       "            279, 151645,    198, 151644,    872,    198,   3862,   2578,    387,\n",
       "            458,   1465,    304,    279,   6291,   3403,   1576,    315,   6853,\n",
       "            315,   8660,    315,    279,   3405,     13,   5209,   4396,    279,\n",
       "           1465,     11,    421,    894,     11,    323,  18130,    279,   6291,\n",
       "             13,  10224,    697,   1590,   4226,   2878,   1124,  79075,   2979,\n",
       "           3417, 151645,    198, 151644,  77091,    198]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>system\\nPlease reason step by step, and put your final answer within \\\\boxed{{}}<|im_end|>\\n<|im_start|>user\\nDetermine the remainder of 71 (mod 3).\\n<|im_end|>\\n<|im_start|>assistant\\n To determine the remainder<|im_end|>\\n<|im_start|>user\\nThere might be an error in the solution above because of lack of understanding of the question. Please correct the error, if any, and rewrite the solution. Put your final answer within \\\\boxed{{}}<|im_end|>\\n<|im_start|>assistant\\n<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|im_start|>system\\nPlease reason step by step, and put your final answer within \\\\boxed{{}}<|im_end|>\\n<|im_start|>user\\nIf $f(x)$ is an even function and $g(x)$ is an odd function, find if $f(g(x^3))$ is even, odd, or neither.\\n\\nEnter \"odd\", \"even\", or \"neither\".\\n<|im_end|>\\n<|im_start|>assistant\\nTo determine whether the<|im_end|>\\n<|im_start|>user\\nThere might be an error in the solution above because of lack of understanding of the question. Please correct the error, if any, and rewrite the solution. Put your final answer within \\\\boxed{{}}<|im_end|>\\n<|im_start|>assistant\\n']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(collated['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [151644,\n",
       "  8948,\n",
       "  198,\n",
       "  5501,\n",
       "  2874,\n",
       "  3019,\n",
       "  553,\n",
       "  3019,\n",
       "  11,\n",
       "  323,\n",
       "  2182,\n",
       "  697,\n",
       "  1590,\n",
       "  4226,\n",
       "  2878,\n",
       "  1124,\n",
       "  79075,\n",
       "  2979,\n",
       "  3417,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  872,\n",
       "  198,\n",
       "  35,\n",
       "  24308,\n",
       "  279,\n",
       "  26313,\n",
       "  315,\n",
       "  220,\n",
       "  22,\n",
       "  16,\n",
       "  320,\n",
       "  2593,\n",
       "  220,\n",
       "  18,\n",
       "  4292,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  77091,\n",
       "  198,\n",
       "  2014,\n",
       "  8253,\n",
       "  279,\n",
       "  26313,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  872,\n",
       "  198,\n",
       "  3862,\n",
       "  2578,\n",
       "  387,\n",
       "  458,\n",
       "  1465,\n",
       "  304,\n",
       "  279,\n",
       "  6291,\n",
       "  3403,\n",
       "  1576,\n",
       "  315,\n",
       "  6853,\n",
       "  315,\n",
       "  8660,\n",
       "  315,\n",
       "  279,\n",
       "  3405,\n",
       "  13,\n",
       "  5209,\n",
       "  4396,\n",
       "  279,\n",
       "  1465,\n",
       "  11,\n",
       "  421,\n",
       "  894,\n",
       "  11,\n",
       "  323,\n",
       "  18130,\n",
       "  279,\n",
       "  6291,\n",
       "  13,\n",
       "  10224,\n",
       "  697,\n",
       "  1590,\n",
       "  4226,\n",
       "  2878,\n",
       "  1124,\n",
       "  79075,\n",
       "  2979,\n",
       "  3417,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  77091,\n",
       "  198]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk('/home/data/v.moskvoretskii/cache/STaSC/test_math_qwen_promtping3/iter_0/data_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "idx = 48\n",
    "\n",
    "ans = ds['star_correction_initial_generation'][idx][0]\n",
    "gt = ds['answer'][idx]\n",
    "\n",
    "\n",
    "final = extract_answer(ans)\n",
    "print(grade_answer(final, gt))\n",
    "\n",
    "if not grade_answer(final, gt):\n",
    "    print(ans)\n",
    "    print(gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = extract_answer(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(3,\\\\frac{\\\\pi}{2})'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('(3,\\\\frac{\\\\pi}{2})', '\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_answer(final, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/home/data/v.moskvoretskii/prm800k/prm800k/math_splits/train.jsonl', lines=True)\n",
    "train = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/home/data/v.moskvoretskii/prm800k/prm800k/math_splits/test.jsonl', lines=True)\n",
    "test = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "math = datasets.DatasetDict({'train': train, 'test': test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cae097839c480e96c863764005ac7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5088d00382f140439d6dbcd996785eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2bb3873ff64b68a76a72c5ea262a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a73834a1fa240c7bba45d26b8bcef12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99afb095f4147c5bd5f3e5172a4a411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/VityaVitalich/MATH500/commit/029807925a6c275a743315e3f806299706a87288', commit_message='Upload dataset', commit_description='', oid='029807925a6c275a743315e3f806299706a87288', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/VityaVitalich/MATH500', endpoint='https://huggingface.co', repo_type='dataset', repo_id='VityaVitalich/MATH500'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.push_to_hub('VityaVitalich/MATH500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12000/12000 [00:00<00:00, 241091.21 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 500/500 [00:00<00:00, 45744.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#math.save_to_disk('../data/math500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/home/data/v.moskvoretskii/prm800k/prm800k/math_splits/train.jsonl', lines=True)\n",
    "df = df[df['level'] == 1]\n",
    "train = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "math = datasets.DatasetDict({'train': train, 'test': test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['problem', 'solution', 'answer', 'subject', 'level', 'unique_id', '__index_level_0__'],\n",
       "        num_rows: 958\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['problem', 'solution', 'answer', 'subject', 'level', 'unique_id'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 958/958 [00:00<00:00, 146690.39 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 500/500 [00:00<00:00, 89278.50 examples/s] \n"
     ]
    }
   ],
   "source": [
    "math.save_to_disk('../data/math500_level1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level\n",
       "5    134\n",
       "4    128\n",
       "3    105\n",
       "2     90\n",
       "1     43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_answer(given_answer='14/3', ground_truth='\\frac{14}{3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      \\left( 3, \\frac{\\pi}{2} \\right)\n",
       "1                                p - q\n",
       "2                         \\frac{14}{3}\n",
       "3                                    9\n",
       "4                        \\text{Evelyn}\n",
       "                    ...               \n",
       "495               (2,12) \\cup (12,102)\n",
       "496                       \\frac{5}{13}\n",
       "497                        \\frac{7}{2}\n",
       "498                                 -1\n",
       "499                          106^\\circ\n",
       "Name: answer, Length: 500, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
